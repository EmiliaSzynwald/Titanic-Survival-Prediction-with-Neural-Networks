{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiiGH8MFV8kEP65M9mL9ND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HofstraDoboli/project-2-project2/blob/main/Project2Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zw1SIprcLcTS",
        "outputId": "3353c38c-95bb-4ae0-f266-45eb59099e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            " \u001b[0m\u001b[01;34mcheckpoints\u001b[0m/                   \u001b[01;34mresults\u001b[0m/\n",
            "'classification test.ipynb'     RL_Project.ipynb\n",
            "'Copy of assignment6.ipynb'     Titanic-Dataset.csv\n",
            " LinRegProject2.ipynb           using_medrxivr.ipynb\n",
            " Project2Classification.ipynb   using_nfcorpus_duplicate.ipynb\n",
            " regressionData.csv             using_nfcorpus.ipynb\n"
          ]
        }
      ],
      "source": [
        "#for Project2 classification\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/MyDrive/Colab Notebooks/'\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "!pip install tensorflow-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gZYzLXjlLy3O",
        "outputId": "839cc237-de23-4435-a380-36fae8277119"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Collecting tensorflow-cpu\n",
            "  Downloading tensorflow_cpu-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow-cpu)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (3.13.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow-cpu)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow-cpu) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
            "Downloading tensorflow_cpu-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (251.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.8/251.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow-cpu\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-cpu-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "import tensorflow as tf\n",
        "tf.autograph.set_verbosity(0)\n",
        "from typing_extensions import runtime"
      ],
      "metadata": {
        "id": "eP4zew3zL1ZN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification problem (NN learns to predict the class)"
      ],
      "metadata": {
        "id": "vat2Dj_VQO-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Titanic-Dataset:\n",
        "The file should have exactly 2 columns:\n",
        "\n",
        "PassengerId (sorted in any order)\n",
        "Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n",
        "\n",
        "PassengerId,Survived:\n",
        "\n",
        "892,0\n",
        "\n",
        "893,1\n",
        "\n",
        "894,0\n",
        "\n",
        "Etc.\n"
      ],
      "metadata": {
        "id": "nfM0RhwbMXTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "collapsed": true,
        "id": "CBvngGEXNfbL",
        "outputId": "52163324-43c7-4863-f203-3d6a53a1461a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name   Age  SibSp  Parch  \\\n",
              "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
              "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
              "4                           Allen, Mr. William Henry  35.0      0      0   \n",
              "\n",
              "             Ticket     Fare Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
              "0         A/5 21171   7.2500   NaN           0         1           0   \n",
              "1          PC 17599  71.2833   C85           1         0           1   \n",
              "2  STON/O2. 3101282   7.9250   NaN           1         0           0   \n",
              "3            113803  53.1000  C123           1         0           0   \n",
              "4            373450   8.0500   NaN           0         1           0   \n",
              "\n",
              "   Embarked_Q  Embarked_S  \n",
              "0           0           1  \n",
              "1           0           0  \n",
              "2           0           1  \n",
              "3           0           1  \n",
              "4           0           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5024a7e7-7cba-4235-964b-781a7160ce7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5024a7e7-7cba-4235-964b-781a7160ce7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5024a7e7-7cba-4235-964b-781a7160ce7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5024a7e7-7cba-4235-964b-781a7160ce7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-005dd84e-28ec-47ed-acf9-0b3634842aae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-005dd84e-28ec-47ed-acf9-0b3634842aae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-005dd84e-28ec-47ed-acf9-0b3634842aae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334044,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.693428597180905,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_female\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked_C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked_Q\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked_S\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6JG0UpCmNkwD",
        "outputId": "1ab32080-4311-4f3f-d312-155fb6a71266"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 15 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Age          714 non-null    float64\n",
            " 5   SibSp        891 non-null    int64  \n",
            " 6   Parch        891 non-null    int64  \n",
            " 7   Ticket       891 non-null    object \n",
            " 8   Fare         891 non-null    float64\n",
            " 9   Cabin        204 non-null    object \n",
            " 10  Sex_female   891 non-null    int64  \n",
            " 11  Sex_male     891 non-null    int64  \n",
            " 12  Embarked_C   891 non-null    int64  \n",
            " 13  Embarked_Q   891 non-null    int64  \n",
            " 14  Embarked_S   891 non-null    int64  \n",
            "dtypes: float64(2), int64(10), object(3)\n",
            "memory usage: 104.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Titanic-Dataset.csv\", thousands=',')\n",
        "\n",
        "# One-hot encode categorical columns (creates Sex_male, Embarked_Q, Embarked_S, etc.)\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=False)\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "# Convert all columns with type 'uint8' or 'bool' to int\n",
        "for col in df.columns:\n",
        "    if df[col].dtype in ['uint8', 'bool']:\n",
        "        df[col] = df[col].astype(int)\n",
        "\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = df.select_dtypes(include=np.number).corr()\n",
        "print(\"Correlation matrix:\\n\", corr_matrix)\n",
        "\n",
        "# 2. EXTRACT OUTPUT COLUMN (Survived)\n",
        "y_np = pd.get_dummies(df['Survived']).to_numpy()  # One-hot encode labels\n",
        "\n",
        "\n",
        "# Get absolute correlation values with the output\n",
        "output_corr = corr_matrix['Survived'].abs()\n",
        "\n",
        "# Select features with correlation >= 0.2, excluding the output itself\n",
        "selected_features = output_corr[output_corr >= 0.2].index.drop('Survived')\n",
        "print(\"Selected features (corr >= 0.2):\", selected_features)\n",
        "\n",
        "# Create the absolute correlation matrix for selected features\n",
        "corr_selected = df[selected_features].corr().abs()\n",
        "\n",
        "# Select the upper triangle of the correlation matrix\n",
        "upper = corr_selected.where(np.triu(np.ones(corr_selected.shape), k=1).astype(bool))\n",
        "\n",
        "# Find columns with any correlation above 0.8\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
        "print(\"Features to drop due to high intercorrelation:\", to_drop)\n",
        "\n",
        "# Final feature set\n",
        "final_features = selected_features.drop(to_drop)\n",
        "print(\"Final selected features:\", final_features)\n",
        "\n",
        "x_np = df[final_features].to_numpy()\n",
        "print(x_np.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P435NHyRVDzq",
        "outputId": "e5cdfcbd-6212-4ade-b594-6220771807da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
            "       'Ticket', 'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Embarked_C',\n",
            "       'Embarked_Q', 'Embarked_S'],\n",
            "      dtype='object')\n",
            "Correlation matrix:\n",
            "              PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
            "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
            "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
            "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
            "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
            "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
            "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
            "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
            "Sex_female     -0.042939  0.543351 -0.131900 -0.093254  0.114631  0.245489   \n",
            "Sex_male        0.042939 -0.543351  0.131900  0.093254 -0.114631 -0.245489   \n",
            "Embarked_C     -0.001205  0.168240 -0.243292  0.036261 -0.059528 -0.011069   \n",
            "Embarked_Q     -0.033606  0.003650  0.221009 -0.022405 -0.026354 -0.081228   \n",
            "Embarked_S      0.022148 -0.155660  0.081720 -0.032523  0.070941  0.063036   \n",
            "\n",
            "                 Fare  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
            "PassengerId  0.012658   -0.042939  0.042939   -0.001205   -0.033606   \n",
            "Survived     0.257307    0.543351 -0.543351    0.168240    0.003650   \n",
            "Pclass      -0.549500   -0.131900  0.131900   -0.243292    0.221009   \n",
            "Age          0.096067   -0.093254  0.093254    0.036261   -0.022405   \n",
            "SibSp        0.159651    0.114631 -0.114631   -0.059528   -0.026354   \n",
            "Parch        0.216225    0.245489 -0.245489   -0.011069   -0.081228   \n",
            "Fare         1.000000    0.182333 -0.182333    0.269335   -0.117216   \n",
            "Sex_female   0.182333    1.000000 -1.000000    0.082853    0.074115   \n",
            "Sex_male    -0.182333   -1.000000  1.000000   -0.082853   -0.074115   \n",
            "Embarked_C   0.269335    0.082853 -0.082853    1.000000   -0.148258   \n",
            "Embarked_Q  -0.117216    0.074115 -0.074115   -0.148258    1.000000   \n",
            "Embarked_S  -0.166603   -0.125722  0.125722   -0.778359   -0.496624   \n",
            "\n",
            "             Embarked_S  \n",
            "PassengerId    0.022148  \n",
            "Survived      -0.155660  \n",
            "Pclass         0.081720  \n",
            "Age           -0.032523  \n",
            "SibSp          0.070941  \n",
            "Parch          0.063036  \n",
            "Fare          -0.166603  \n",
            "Sex_female    -0.125722  \n",
            "Sex_male       0.125722  \n",
            "Embarked_C    -0.778359  \n",
            "Embarked_Q    -0.496624  \n",
            "Embarked_S     1.000000  \n",
            "Selected features (corr >= 0.2): Index(['Pclass', 'Fare', 'Sex_female', 'Sex_male'], dtype='object')\n",
            "Features to drop due to high intercorrelation: ['Sex_male']\n",
            "Final selected features: Index(['Pclass', 'Fare', 'Sex_female'], dtype='object')\n",
            "(891, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### B. Normalize the data (subtract the mean and divide by the variance).\n",
        "### Then split the data into training and validation (80% training/20% validation).\n",
        "\n",
        "\n",
        "# 1. Split data into training and validation sets\n",
        "# First split: 80% train, 20% temp (val+test)\n",
        "x_np_train, x_np_temp, y_np_train, y_np_temp = train_test_split(\n",
        "    x_np, y_np, test_size=0.2, shuffle=True, random_state=2\n",
        ")\n",
        "\n",
        "# Second split: 10% val, 10% test\n",
        "x_np_val, x_np_test, y_np_val, y_np_test = train_test_split(\n",
        "    x_np_temp, y_np_temp, test_size=0.5, shuffle=True, random_state=2\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", x_np_train.shape)\n",
        "print(\"Val shape:\", x_np_val.shape)\n",
        "print(\"Test shape:\", x_np_test.shape)\n",
        "\n",
        "# 2. Normalize features (fit only on training)\n",
        "x_scaler = StandardScaler()\n",
        "x_np_train_scaled = x_scaler.fit_transform(x_np_train)\n",
        "x_np_val_scaled   = x_scaler.transform(x_np_val)\n",
        "x_np_test_scaled  = x_scaler.transform(x_np_test)\n",
        "\n",
        "# 3. Normalize labels (fit only on training)\n",
        "y_scaler = StandardScaler()\n",
        "y_np_train_scaled = y_scaler.fit_transform(y_np_train)\n",
        "y_np_val_scaled   = y_scaler.transform(y_np_val)\n",
        "y_np_test_scaled  = y_scaler.transform(y_np_test)\n",
        "\n",
        "# 4. Convert to PyTorch tensors\n",
        "x_train_tensor = torch.from_numpy(x_np_train_scaled).float()\n",
        "x_val_tensor   = torch.from_numpy(x_np_val_scaled).float()\n",
        "x_test_tensor  = torch.from_numpy(x_np_test_scaled).float()\n",
        "\n",
        "y_train_indices = torch.from_numpy(np.argmax(y_np_train, axis=1)).long()\n",
        "y_val_indices   = torch.from_numpy(np.argmax(y_np_val, axis=1)).long()\n",
        "y_test_indices  = torch.from_numpy(np.argmax(y_np_test, axis=1)).long()\n",
        "\n",
        "train_data = [(x_train_tensor[i], y_train_indices[i]) for i in range(x_train_tensor.shape[0])]\n",
        "val_data   = [(x_val_tensor[i],   y_val_indices[i])   for i in range(x_val_tensor.shape[0])]\n",
        "test_data  = [(x_test_tensor[i],  y_test_indices[i])  for i in range(x_test_tensor.shape[0])]\n",
        "\n",
        "trainloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valloader   = DataLoader(val_data, batch_size=8)\n",
        "testloader  = DataLoader(test_data, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bEl8DUcHp_aT",
        "outputId": "f6a28de4-017b-4213-ef15-ed0fb5ad6ad0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (712, 3)\n",
            "Val shape: (89, 3)\n",
            "Test shape: (90, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Train a NN for each problem. Compute the training loss and the validation loss as in the examples we did in class.\n",
        "# Try different architectures: vary the number of hidden layers, number of hidden neurons, learning rate, optimization algorithm (SGD or Adam).\n",
        "# Compare the models in terms of training and validation error. Comment on which models gave you better results and why."
      ],
      "metadata": {
        "id": "xT4S5KtXsHO3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 15)\n",
        "        self.layer2 = nn.Linear(15, 12) #2 hidden layers\n",
        "        self.layer3 = nn.Linear(12, 2)  # 2 output classes (survived/died)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = self.layer3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ruonio9S3c0P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(x_train_tensor.shape[1])\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(n_epochs, model, train_loader, val_loader, optimizer, loss_fn):\n",
        "    for epoch in range(n_epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            ym = model(xb)\n",
        "            loss = loss_fn(ym, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(ym.data, 1)\n",
        "            total += yb.size(0)\n",
        "            correct += (predicted == yb).sum().item()\n",
        "        acc = 100 * correct / total\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Train Acc: {acc:.2f}%\")\n",
        "        # Validation\n",
        "        if epoch % 10 == 0:\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    ym_val = model(xb)\n",
        "                    loss_val = loss_fn(ym_val, yb)\n",
        "                    val_loss += loss_val.item()\n",
        "                    _, predicted = torch.max(ym_val.data, 1)\n",
        "                    val_total += yb.size(0)\n",
        "                    val_correct += (predicted == yb).sum().item()\n",
        "            val_acc = 100 * val_correct / val_total\n",
        "            val_loss = val_loss / len(val_loader)\n",
        "            print(f\"         Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    print(\"Training complete.\")\n",
        "    return train_loss, val_loss\n",
        "\n",
        "train_loss, val_loss = train_model(\n",
        "    n_epochs=100,\n",
        "    model=model,\n",
        "    train_loader=trainloader,\n",
        "    val_loader=valloader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c237Jm-V3eHt",
        "outputId": "0abaa023-21b9-4446-e1ea-566a275a0229"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 0.5616, Train Acc: 72.19%\n",
            "         Val Loss: 0.4506, Val Acc: 78.65%\n",
            "Epoch 10, Train Loss: 0.4285, Train Acc: 81.32%\n",
            "         Val Loss: 0.4268, Val Acc: 79.78%\n",
            "Epoch 20, Train Loss: 0.4539, Train Acc: 79.78%\n",
            "         Val Loss: 0.4036, Val Acc: 80.90%\n",
            "Epoch 30, Train Loss: 0.4385, Train Acc: 80.34%\n",
            "         Val Loss: 0.4056, Val Acc: 82.02%\n",
            "Epoch 40, Train Loss: 0.4313, Train Acc: 81.32%\n",
            "         Val Loss: 0.4002, Val Acc: 79.78%\n",
            "Epoch 50, Train Loss: 0.4339, Train Acc: 80.48%\n",
            "         Val Loss: 0.4587, Val Acc: 75.28%\n",
            "Epoch 60, Train Loss: 0.4253, Train Acc: 81.04%\n",
            "         Val Loss: 0.3810, Val Acc: 82.02%\n",
            "Epoch 70, Train Loss: 0.4212, Train Acc: 81.04%\n",
            "         Val Loss: 0.4158, Val Acc: 79.78%\n",
            "Epoch 80, Train Loss: 0.4274, Train Acc: 81.18%\n",
            "         Val Loss: 0.4139, Val Acc: 82.02%\n",
            "Epoch 90, Train Loss: 0.4128, Train Acc: 81.74%\n",
            "         Val Loss: 0.4003, Val Acc: 82.02%\n",
            "Epoch 100, Train Loss: 0.4187, Train Acc: 81.46%\n",
            "         Val Loss: 0.3912, Val Acc: 82.02%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as t\n",
        "\n",
        "soft_max = t.nn.Softmax(dim=1)\n",
        "\n",
        "# Training set predictions\n",
        "y_m_train_pred = soft_max(model(x_train_tensor))\n",
        "y_m_train_pred = t.argmax(y_m_train_pred, dim=1)\n",
        "\n",
        "# Validation set predictions\n",
        "y_m_val_pred = soft_max(model(x_val_tensor))\n",
        "y_m_val_pred = t.argmax(y_m_val_pred, dim=1)\n",
        "\n",
        "# Accuracy calculations\n",
        "correct_pred_train = t.sum(y_m_train_pred == y_train_indices) / y_m_train_pred.shape[0]\n",
        "correct_pred_val = t.sum(y_m_val_pred == y_val_indices) / y_m_val_pred.shape[0]\n",
        "\n",
        "print(f\"Final Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "print(\"Final Training accuracy = \", correct_pred_train.item())\n",
        "print(\"Final Validation accuracy = \", correct_pred_val.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8UDVg88FW9E",
        "outputId": "df0d9634-74e5-44bc-f579-e7ff566c9518"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Loss: 0.4187\n",
            "Final Validation Loss: 0.3912\n",
            "Final Training accuracy =  0.8202247023582458\n",
            "Final Validation accuracy =  0.8202247023582458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            ym = model(xb)\n",
        "            loss = loss_fn(ym, yb)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(ym.data, 1)\n",
        "            test_total += yb.size(0)\n",
        "            test_correct += (predicted == yb).sum().item()\n",
        "    test_acc = 100 * test_correct / test_total\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
        "    return test_loss, test_acc\n",
        "\n",
        "# After training:\n",
        "evaluate_model(model, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfTglTLclnW",
        "outputId": "ea26337a-07a9-43df-b0ac-087ee8baea98"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5773, Test Acc: 72.22%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.577253465851148, 72.22222222222223)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing:"
      ],
      "metadata": {
        "id": "dA_eRxFgDE3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, output_dim=2):\n",
        "        \"\"\"\n",
        "        input_dim: int, number of input features\n",
        "        hidden_layers: list of int, e.g. [15, 12] for two layers with 15 and 12 neurons\n",
        "        output_dim: int, number of output classes (2 for Titanic)\n",
        "        \"\"\"\n",
        "        super(FlexibleModel, self).__init__()\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(prev_dim, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_dim = h\n",
        "        layers.append(nn.Linear(prev_dim, output_dim))  # Output layer\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "i-afvWUiDBNf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 hidden layers with 15 and 12 neurons-my current setup\n",
        "model1 = FlexibleModel(input_dim=x_train_tensor.shape[1], hidden_layers=[15, 12])\n",
        "\n",
        "# 2 hidden layers with\n",
        "model2 = FlexibleModel(input_dim=x_train_tensor.shape[1], hidden_layers=[20, 30, 8])\n",
        "\n",
        "# 3 hidden layers with 32, 16, and 8 neurons\n",
        "model3 = FlexibleModel(input_dim=x_train_tensor.shape[1], hidden_layers=[32, 16, 8])\n"
      ],
      "metadata": {
        "id": "1_Zoe4d-DD6s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model1.parameters(), lr=0.05, momentum=0.9)\n",
        "train_model(\n",
        "    n_epochs=100,\n",
        "    model=model1,\n",
        "    train_loader=trainloader,\n",
        "    val_loader=valloader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=0.05, momentum=0.9)\n",
        "train_model(\n",
        "    n_epochs=100,\n",
        "    model=model2,\n",
        "    train_loader=trainloader,\n",
        "    val_loader=valloader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model3.parameters(), lr=0.05, momentum=0.9)\n",
        "train_model(\n",
        "    n_epochs=100,\n",
        "    model=model3,\n",
        "    train_loader=trainloader,\n",
        "    val_loader=valloader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mzLhf56ADLjp",
        "outputId": "d588888c-4770-48f8-cf0e-3212f7c8eb9a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 0.5857, Train Acc: 69.52%\n",
            "         Val Loss: 0.4096, Val Acc: 80.90%\n",
            "Epoch 10, Train Loss: 0.4399, Train Acc: 81.18%\n",
            "         Val Loss: 0.3961, Val Acc: 80.90%\n",
            "Epoch 20, Train Loss: 0.4257, Train Acc: 81.18%\n",
            "         Val Loss: 0.4272, Val Acc: 82.02%\n",
            "Epoch 30, Train Loss: 0.4367, Train Acc: 81.18%\n",
            "         Val Loss: 0.4209, Val Acc: 79.78%\n",
            "Epoch 40, Train Loss: 0.4425, Train Acc: 79.63%\n",
            "         Val Loss: 0.4286, Val Acc: 82.02%\n",
            "Epoch 50, Train Loss: 0.4240, Train Acc: 80.76%\n",
            "         Val Loss: 0.4244, Val Acc: 75.28%\n",
            "Epoch 60, Train Loss: 0.4262, Train Acc: 82.30%\n",
            "         Val Loss: 0.4056, Val Acc: 79.78%\n",
            "Epoch 70, Train Loss: 0.4376, Train Acc: 80.62%\n",
            "         Val Loss: 0.3731, Val Acc: 80.90%\n",
            "Epoch 80, Train Loss: 0.4313, Train Acc: 81.04%\n",
            "         Val Loss: 0.3792, Val Acc: 82.02%\n",
            "Epoch 90, Train Loss: 0.4174, Train Acc: 80.34%\n",
            "         Val Loss: 0.3983, Val Acc: 82.02%\n",
            "Epoch 100, Train Loss: 0.4246, Train Acc: 81.04%\n",
            "         Val Loss: 0.4112, Val Acc: 79.78%\n",
            "Training complete.\n",
            "Epoch 0, Train Loss: 0.6544, Train Acc: 63.06%\n",
            "         Val Loss: 0.6242, Val Acc: 59.55%\n",
            "Epoch 10, Train Loss: 0.4558, Train Acc: 79.49%\n",
            "         Val Loss: 0.4376, Val Acc: 76.40%\n",
            "Epoch 20, Train Loss: 0.4359, Train Acc: 81.88%\n",
            "         Val Loss: 0.4098, Val Acc: 79.78%\n",
            "Epoch 30, Train Loss: 0.4281, Train Acc: 80.06%\n",
            "         Val Loss: 0.4379, Val Acc: 75.28%\n",
            "Epoch 40, Train Loss: 0.4441, Train Acc: 80.76%\n",
            "         Val Loss: 0.4407, Val Acc: 75.28%\n",
            "Epoch 50, Train Loss: 0.4440, Train Acc: 80.48%\n",
            "         Val Loss: 0.4099, Val Acc: 75.28%\n",
            "Epoch 60, Train Loss: 0.4441, Train Acc: 82.02%\n",
            "         Val Loss: 0.4011, Val Acc: 79.78%\n",
            "Epoch 70, Train Loss: 0.4242, Train Acc: 80.90%\n",
            "         Val Loss: 0.3789, Val Acc: 82.02%\n",
            "Epoch 80, Train Loss: 0.4256, Train Acc: 81.32%\n",
            "         Val Loss: 0.3794, Val Acc: 82.02%\n",
            "Epoch 90, Train Loss: 0.4261, Train Acc: 81.46%\n",
            "         Val Loss: 0.3825, Val Acc: 82.02%\n",
            "Epoch 100, Train Loss: 0.4254, Train Acc: 81.46%\n",
            "         Val Loss: 0.3881, Val Acc: 82.02%\n",
            "Training complete.\n",
            "Epoch 0, Train Loss: 0.6134, Train Acc: 65.03%\n",
            "         Val Loss: 0.4407, Val Acc: 80.90%\n",
            "Epoch 10, Train Loss: 0.4479, Train Acc: 81.60%\n",
            "         Val Loss: 0.4026, Val Acc: 82.02%\n",
            "Epoch 20, Train Loss: 0.4444, Train Acc: 79.07%\n",
            "         Val Loss: 0.3950, Val Acc: 82.02%\n",
            "Epoch 30, Train Loss: 0.4340, Train Acc: 79.92%\n",
            "         Val Loss: 0.4328, Val Acc: 75.28%\n",
            "Epoch 40, Train Loss: 0.4175, Train Acc: 81.18%\n",
            "         Val Loss: 0.4035, Val Acc: 82.02%\n",
            "Epoch 50, Train Loss: 0.4283, Train Acc: 80.62%\n",
            "         Val Loss: 0.4064, Val Acc: 75.28%\n",
            "Epoch 60, Train Loss: 0.4360, Train Acc: 81.60%\n",
            "         Val Loss: 0.3890, Val Acc: 82.02%\n",
            "Epoch 70, Train Loss: 0.4254, Train Acc: 79.63%\n",
            "         Val Loss: 0.3590, Val Acc: 82.02%\n",
            "Epoch 80, Train Loss: 0.4496, Train Acc: 79.63%\n",
            "         Val Loss: 0.4016, Val Acc: 82.02%\n",
            "Epoch 90, Train Loss: 0.4257, Train Acc: 81.32%\n",
            "         Val Loss: 0.4123, Val Acc: 79.78%\n",
            "Epoch 100, Train Loss: 0.4361, Train Acc: 81.32%\n",
            "         Val Loss: 0.3580, Val Acc: 82.02%\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.43610338607560034, 0.35803106054080064)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.eval()\n",
        "with torch.no_grad():\n",
        "    y_m_train = model1(x_train_tensor)\n",
        "    y_m_train = torch.argmax(y_m_train, dim=1)\n",
        "    train_acc = (y_m_train == y_train_indices).float().mean().item()\n",
        "    print(\"Final Training accuracy = \", train_acc)\n",
        "\n",
        "    y_m_val = model1(x_val_tensor)\n",
        "    y_m_val = torch.argmax(y_m_val, dim=1)\n",
        "    val_acc = (y_m_val == y_val_indices).float().mean().item()\n",
        "    print(\"Final Validation accuracy = \", val_acc)\n",
        "\n",
        "\n",
        "model2.eval()\n",
        "with torch.no_grad():\n",
        "    y_m_train = model2(x_train_tensor)\n",
        "    y_m_train = torch.argmax(y_m_train, dim=1)\n",
        "    train_acc = (y_m_train == y_train_indices).float().mean().item()\n",
        "    print(\"Final Training accuracy = \", train_acc)\n",
        "\n",
        "    y_m_val = model2(x_val_tensor)\n",
        "    y_m_val = torch.argmax(y_m_val, dim=1)\n",
        "    val_acc = (y_m_val == y_val_indices).float().mean().item()\n",
        "    print(\"Final Validation accuracy = \", val_acc)\n",
        "\n",
        "model3.eval()\n",
        "with torch.no_grad():\n",
        "    y_m_train = model3(x_train_tensor)\n",
        "    y_m_train = torch.argmax(y_m_train, dim=1)\n",
        "    train_acc = (y_m_train == y_train_indices).float().mean().item()\n",
        "    print(\"Final Training accuracy = \", train_acc)\n",
        "\n",
        "    y_m_val = model3(x_val_tensor)\n",
        "    y_m_val = torch.argmax(y_m_val, dim=1)\n",
        "    val_acc = (y_m_val == y_val_indices).float().mean().item()\n",
        "    print(\"Final Validation accuracy = \", val_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUAAJk5HDZpo",
        "outputId": "a478f5e6-f454-410f-c57c-b585bed79a15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training accuracy =  0.8146067261695862\n",
            "Final Validation accuracy =  0.7977527976036072\n",
            "Final Training accuracy =  0.817415714263916\n",
            "Final Validation accuracy =  0.8202247023582458\n",
            "Final Training accuracy =  0.8160112500190735\n",
            "Final Validation accuracy =  0.8202247023582458\n"
          ]
        }
      ]
    }
  ]
}